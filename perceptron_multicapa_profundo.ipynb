{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9M_ldCoUz5SQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "def bias_add(V):\n",
        "    bias = -np.ones( (len(V),1) )\n",
        "    return np.concatenate( (V,bias), axis=1)\n",
        "\n",
        "def bias_sub(V):\n",
        "    return V[:,:-1] # Saco la ultima columna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def activation(X): \n",
        "    \n",
        "    Y = [] # L capas Y_o, Y_1, Y_2, .... Y_l-1\n",
        "    i = 0\n",
        "    P = len(X)\n",
        "    for s in S: # S variable global con los sizes de las capas \n",
        "        if i == len(S)-1:\n",
        "            Y.append( np.zeros((P,s)) )\n",
        "            i += 1\n",
        "        else:\n",
        "            Y.append( np.zeros((P,s+1)) )\n",
        "            i += 1\n",
        "        \n",
        "    Y[0][:] = bias_add(X)\n",
        "    \n",
        "    for k in range(1,len(S)-1):\n",
        "        Y[k][:] = bias_add( np.tanh( np.dot(Y[k-1],W[k]) ) ) # W global (se arman a parte)\n",
        "        \n",
        "    Y[-1][:] = np.tanh( np.dot(Y[-2],W[-1]) )\n",
        "    return Y  "
      ],
      "metadata": {
        "id": "-p1FqNBaz9_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def correction(Y,Z):\n",
        "    delta_W = [0] # primer elemento vacio\n",
        "    \n",
        "    for i in range(1,len(S)): # S variable global con los sizes de las capas \n",
        "        delta_W.append( np.zeros( (S[i-1]+1,S[i]) ) )\n",
        "        \n",
        "    L = len(S) \n",
        "    E = [0]*L # size L \n",
        "    D = [0]*L # size L\n",
        "    d = [0]*L # size L\n",
        "    \n",
        "    E[L-1] =  Z - Y[-1] \n",
        "    d[L-1] = 1 - Y[-1]**2\n",
        "    D[L-1] = E[-1]*d[-1] \n",
        "        \n",
        "    for k in reversed(np.arange(1,L)):\n",
        "        delta_W[k] = lr * np.dot( Y[k-1].T, D[k]) # lr = learning rate (variable global)\n",
        "        E[k] = np.dot( D[k], W[k].T )\n",
        "        d[k] = ( 1 - Y[k-1]**2 )\n",
        "        D[k-1] = ( bias_sub( E[k]*d[k] ) )\n",
        "    return delta_W"
      ],
      "metadata": {
        "id": "Od9scpbt0AiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adaptation(W,delta_W):\n",
        "  L = len(S) # S Variable global\n",
        "  for k in range(1,L-1):\n",
        "    W[k] += delta_W[k]\n",
        "  return W"
      ],
      "metadata": {
        "id": "5l0BuBUD3wIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def estimation(Z,Y):\n",
        "  est = np.mean( np.square(Z - Y) )\n",
        "  return est"
      ],
      "metadata": {
        "id": "kkKXeSAi4F8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(X, Z, S, W, lr, eps, epoch):\n",
        "\n",
        "  error = 1\n",
        "  iter = 0\n",
        "  errores = []\n",
        "  while error > eps and iter < epoch:\n",
        "\n",
        "    Y = activation(X)\n",
        "    delta_w = correction(Y,Z)\n",
        "    W = adaptation(W,delta_w)\n",
        "    error = estimation(Z,Y[-1])\n",
        "\n",
        "    errores.append(error)\n",
        "    iter += 1\n",
        "\n",
        "  return errores"
      ],
      "metadata": {
        "id": "1ISFuo9ektko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_stochastic(X, Z, S, W, lr, eps, epoch):\n",
        "    \n",
        "  error = 1\n",
        "  iter = 0\n",
        "  errores = []\n",
        "  P = len(X)\n",
        "  while error > eps and iter < epoch:\n",
        "    e = 0\n",
        "    stochastic = np.random.permutation(P)\n",
        "    for h in stochastic:\n",
        "        Xh = X[h:h+1]\n",
        "        Zh = Z[h:h+1]\n",
        "\n",
        "        Y = activation(Xh)\n",
        "        delta_w = correction(Y,Zh)\n",
        "        W = adaptation(W,delta_w)\n",
        "        e += np.sum( np.square( Z - Y[-1] ))\n",
        "        \n",
        "    error = e/P\n",
        "    errores.append(error)\n",
        "    iter += 1\n",
        "\n",
        "  return errores"
      ],
      "metadata": {
        "id": "wgJXJ8Y_kvFz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}